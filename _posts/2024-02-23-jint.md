---
layout: post
title: Paper - A Procedural Constructive Learning Mechanism with Deep Reinforcement Learning for Cognitive Agents
cover-img: /assets/img/jint.png
thumbnail-img: /assets/img/jint.png
share-img: /assets/img/jint.png
tags: [springer, jint, paper, en]
---

Work published in 2024 at JINT Journal of Intelligent & Robotic Systems. presents a learning strategy that amalgamates deep reinforcement learning with procedural learning, mirroring the incremental learning process observed in human sensorimotor development. This approach is embedded within the CONAIM cognitive-attentional architecture, leveraging the cognitive tools of CST.

### A Procedural Constructive Learning Mechanism with Deep Reinforcement Learning for Cognitive Agents / 2024 / JINT Journal of Intelligent & Robotic Systems


Recent advancements in AI and deep learning have created a growing demand for artificial agents capable of performing tasks within increasingly complex environments. To address the challenges associated with continuous learning constraints and knowledge capacity in this context, cognitive architectures inspired by human cognition have gained significance. This study contributes to existing research by introducing a cognitive-attentional system employing a constructive neural network-based learning approach for continuous acquisition of procedural knowledge. We replace an incremental tabular Reinforcement Learning algorithm with a constructive neural network deep reinforcement learning mechanism for continuous sensorimotor knowledge acquisition, thereby enhancing the overall learning capacity. The primary emphasis of this modification centers on optimizing memory utilization and reducing training time. Our study presents a learning strategy that amalgamates deep reinforcement learning with procedural learning, mirroring the incremental learning process observed in human sensorimotor development. This approach is embedded within the CONAIM cognitive-attentional architecture, leveraging the cognitive tools of CST. The proposed learning mechanism allows the model to dynamically create and modify elements in its procedural memory, facilitating the reuse of previously acquired functions and procedures. Additionally, it equips the model with the capability to combine learned elements to effectively adapt to complex scenarios. A constructive neural network was employed, initiating with an initial hidden layer comprising one neuron. However, it possesses the capacity to adapt its internal architecture in response to its performance in procedural and sensorimotor learning tasks, inserting new hidden layers or neurons. Experimentation conducted through simulations involving a humanoid robot demonstrates the successful resolution of tasks that were previously unsolved through incremental knowledge acquisition. Throughout the training phase, the constructive agent achieved a minimum of 40% greater rewards and executed 8% more actions when compared to other agents. In the subsequent testing phase, the constructive agent exhibited a 15% increase in the number of actions performed in contrast to its counterparts.

de Lellis Rossi, L., Rohmer, E., Dornhofer Paro Costa, P. et al. A Procedural Constructive Learning Mechanism with Deep Reinforcement Learning for Cognitive Agents. J Intell Robot Syst 110, 38 (2024).


[https://doi.org/10.1007/s10846-024-02064-9](https://doi.org/10.1007/s10846-024-02064-9)


